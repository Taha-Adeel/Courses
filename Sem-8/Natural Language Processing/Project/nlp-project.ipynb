{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T00:50:23.920993Z","iopub.status.busy":"2024-04-28T00:50:23.920599Z","iopub.status.idle":"2024-04-28T00:50:35.990665Z","shell.execute_reply":"2024-04-28T00:50:35.989499Z","shell.execute_reply.started":"2024-04-28T00:50:23.920960Z"},"trusted":true},"outputs":[],"source":["%pip install -q -U transformers accelerate bitsandbytes"]},{"cell_type":"markdown","metadata":{},"source":["# Setting the Quantization"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T00:50:35.992979Z","iopub.status.busy":"2024-04-28T00:50:35.992660Z","iopub.status.idle":"2024-04-28T00:50:36.000091Z","shell.execute_reply":"2024-04-28T00:50:35.999031Z","shell.execute_reply.started":"2024-04-28T00:50:35.992950Z"},"trusted":true},"outputs":[],"source":["from transformers import BitsAndBytesConfig\n","\n","# To reduce the memory usage, we use 4-bit floating points instead of default 32-bit ones\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit = True,\n","    bnb_4bit_quant_type = \"nf4\",\n","    bnb_4bit_use_double_quant = True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Model Loading"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T00:50:36.001546Z","iopub.status.busy":"2024-04-28T00:50:36.001263Z","iopub.status.idle":"2024-04-28T00:52:41.214947Z","shell.execute_reply":"2024-04-28T00:52:41.214119Z","shell.execute_reply.started":"2024-04-28T00:50:36.001521Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38849183b189423da03995dc13ed6312","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM \n","import torch\n","\n","model_name = \"/kaggle/input/mistral/pytorch/7b-v0.1-hf/1\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config = bnb_config,\n","    torch_dtype = torch.bfloat16,\n","    device_map = \"auto\",\n","    trust_remote_code = True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Creating the Pipeline"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T00:52:41.217489Z","iopub.status.busy":"2024-04-28T00:52:41.217120Z","iopub.status.idle":"2024-04-28T00:52:48.424770Z","shell.execute_reply":"2024-04-28T00:52:48.423668Z","shell.execute_reply.started":"2024-04-28T00:52:41.217458Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from transformers import pipeline \n","\n","pipe = pipeline(\n","    \"text-generation\",\n","    model = model,\n","    tokenizer = tokenizer,\n","    torch_dtype = torch.bfloat16,\n","    device_map = \"auto\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Text-Generation"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T00:52:48.426974Z","iopub.status.busy":"2024-04-28T00:52:48.426172Z","iopub.status.idle":"2024-04-28T00:52:57.805711Z","shell.execute_reply":"2024-04-28T00:52:57.804607Z","shell.execute_reply.started":"2024-04-28T00:52:48.426936Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Yay the model is working. Tell srikaran that mistral ka ran.\n","\n","Comment: @RaviTeja: You should post the `console.log(data)` result in the question.\n","\n","Comment: @RaviTeja: Yes you have a valid response, try to parse it as json.\n","\n","Comment: @RaviTeja: You are not parsing the response. Just do `data.result` and you will see the object.\n","\n","Comment: @RaviTeja: What you are getting is a j\n"]}],"source":["prompt = \"Yay the model is working. Tell srikaran that mistral ka ran.\"\n","\n","sequence = pipe(\n","    prompt,\n","    do_sample = True,\n","    top_k = 50,\n","    top_p = 0.95,\n","    max_new_tokens = 100,\n","    temperature = 0.7,\n","    num_return_sequences = 1,\n",")\n","\n","print(sequence[0][\"generated_text\"])"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"modelInstanceId":3899,"sourceId":5111,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30559,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}

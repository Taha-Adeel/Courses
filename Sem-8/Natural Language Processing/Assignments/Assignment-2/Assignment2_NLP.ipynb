{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "U8EebE8UyqY6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tCuFfMx50O_z"
      },
      "outputs": [],
      "source": [
        "# Set path to the input dataset\n",
        "filePath = open(\"./archive/Harry_Potter_all_books_preprocessed.txt\")\n",
        "inputText = filePath.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UENQYox0ASHU"
      },
      "outputs": [],
      "source": [
        "# Take the first 10,000 words from the input text\n",
        "spaceCount = 0\n",
        "totalWordsRequired = 10000\n",
        "N = 0\n",
        "while spaceCount < totalWordsRequired:\n",
        "    if inputText[N] == ' ':\n",
        "        spaceCount += 1\n",
        "    N += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9t5lUxZAQ_Y",
        "outputId": "ae532e27-fe2b-4ad1-c84b-45789d830bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of characters in first 10000 words: 53909\n",
            "Sample text: THE BOY WHO LIVED Mr and Mrs Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you very much .They were the last people youd expect to be involved in anything strange or mysterious because they just didnt hold with such nonsense .Mr Dursley was the director \n"
          ]
        }
      ],
      "source": [
        "text = inputText[:N]\n",
        "print(f'Number of characters in first {totalWordsRequired} words: {len(text)}')\n",
        "print(f'Sample text: {text[:300]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "terZIFAJrTq1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 660\n",
            "Sample sentence: yes that would be it\n"
          ]
        }
      ],
      "source": [
        "sentences_text = text.split(' .')\n",
        "print(f'Number of sentences: {len(sentences_text)}')\n",
        "print(f'Sample sentence: {sentences_text[35]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_B4Wc4d2_4a"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHijE2WQ42Ms"
      },
      "source": [
        "## Remove punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3rmt5DZR28Sz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/taha_adeel/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "def remPunctuations(text):\n",
        "    # table is a translation table for removing the punctuation marks from the words\n",
        "    table = str.maketrans({key: None for key in string.punctuation})\n",
        "    translated = text.translate(table)\n",
        "    return translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tkzbJBdtr0ll"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed sample sentence: the boy who lived mr and mrs dursley of number four privet drive were proud to say that they were perfectly normal thank you very much\n"
          ]
        }
      ],
      "source": [
        "punc_removed_sentences_text = []\n",
        "for s in sentences_text:\n",
        "    punc_removed_sentences_text.append(remPunctuations(s).lower())\n",
        "print(f'Preprocessed sample sentence: {punc_removed_sentences_text[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGvVpVcF5KWf"
      },
      "source": [
        "## Tokenize the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GgF7dVkL4AWR"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Takes a string input and returns a list of tokens\n",
        "def tokenize(text):\n",
        "    return word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QLIuKc_5DY9",
        "outputId": "f4fdc1fe-2c5c-4c3c-fda8-5cedad63375f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample sentence tokens: ['the', 'boy', 'who', 'lived', 'mr', 'and', 'mrs', 'dursley', 'of', 'number', 'four', 'privet', 'drive', 'were', 'proud', 'to', 'say', 'that', 'they', 'were', 'perfectly', 'normal', 'thank', 'you', 'very', 'much']\n"
          ]
        }
      ],
      "source": [
        "sentences_tokens = []\n",
        "for s in punc_removed_sentences_text:\n",
        "    sentences_tokens.append(tokenize(s))\n",
        "\n",
        "print(f'Sample sentence tokens: {sentences_tokens[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qwUXItv5iEt"
      },
      "source": [
        "# Fitting bigram language models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7gfo6V336y78"
      },
      "outputs": [],
      "source": [
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "ngram_order = 2\n",
        "train_data, vocab_data = padded_everygram_pipeline(\n",
        "                            ngram_order,\n",
        "                            sentences_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u_C7Yxw-Xjk"
      },
      "source": [
        "## MLE model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "To_qXOn85EIT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: 1905\n",
            "Voabulary lookup sample: ('mr', 'dursley', 'was', 'the', 'director', 'of', 'a', 'firm', 'called', 'grunnings', 'which', 'made', 'drills')\n"
          ]
        }
      ],
      "source": [
        "from nltk.lm import MLE\n",
        "\n",
        "mle_lm = MLE(ngram_order)\n",
        "mle_lm.fit(train_data, vocab_data)\n",
        "\n",
        "print(f'Vocabulary: {len(mle_lm.vocab)}')\n",
        "print(f'Voabulary lookup sample: {mle_lm.vocab.lookup(sentences_tokens[2])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMZg2hSi913Z",
        "outputId": "55c991d7-2851-4bc0-fa70-0a0b30a56946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentence for Harry Potter: \n",
            "harry potter was a grip on yourself should have to brazil here was in his bed </s> while dudley </s> going to\n"
          ]
        }
      ],
      "source": [
        "predicted_sentence_1 = mle_lm.generate(20, text_seed=['harry', 'potter'])\n",
        "predicted_sentence_1 = 'harry potter ' + ' '.join(predicted_sentence_1)\n",
        "\n",
        "print(f'Predicted sentence for Harry Potter: \\n{predicted_sentence_1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igR4NK3YBgxe",
        "outputId": "5330a8fc-db5b-4374-db9b-68de590798ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentence for Dumbledore: \n",
            "Dumbledore bowed his last even worth just didnt seem to mention of privet drive </s> mancrushing pythons </s> bed and worried\n"
          ]
        }
      ],
      "source": [
        "# mle_lm.generate(20, text_seed=['Dumbledore'])\n",
        "predicted_sentence_2 = mle_lm.generate(20, text_seed=['dumbledore'])\n",
        "predicted_sentence_2 = 'Dumbledore ' + ' '.join(predicted_sentence_2)\n",
        "\n",
        "print(f'Predicted sentence for Dumbledore: \\n{predicted_sentence_2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tg9I5r2-YbK"
      },
      "source": [
        "## Kneser-Ney model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QUa6tPd3-OG4"
      },
      "outputs": [],
      "source": [
        "from nltk.lm.models import KneserNeyInterpolated\n",
        "\n",
        "ngram_order = 2\n",
        "train_data, vocab_data = padded_everygram_pipeline(\n",
        "                            ngram_order,\n",
        "                            sentences_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq2QTv-aCpQI",
        "outputId": "8862becb-5f3f-4476-fa52-846970e69edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: 1905\n"
          ]
        }
      ],
      "source": [
        "kn_lm = KneserNeyInterpolated(ngram_order)\n",
        "kn_lm.fit(train_data, vocab_data)\n",
        "\n",
        "print(f'Vocabulary: {len(kn_lm.vocab)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFF4vhJeCqnI",
        "outputId": "c4ea58b8-82f3-44b7-8988-ec84396ea549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentence for Harry Potter: \n",
            "harry potter day </s> whatever everyone knows youre here without it had said that when september came up their sleeping pattern </s>\n"
          ]
        }
      ],
      "source": [
        "predicted_sentence_1 = kn_lm.generate(20, text_seed=['harry', 'potter'])\n",
        "predicted_sentence_1 = 'harry potter ' + ' '.join(predicted_sentence_1)\n",
        "\n",
        "print(f'Predicted sentence for Harry Potter: \\n{predicted_sentence_1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgI3Bqd2QL_j",
        "outputId": "dc47b98e-aec4-44c7-83ed-bdcb46b69993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentence for Dumbledore: \n",
            "Dumbledore bowed to be back down on the stairs was the bill and the dream before the kitchen the same heavy\n"
          ]
        }
      ],
      "source": [
        "predicted_sentence_2 = kn_lm.generate(20, text_seed=['dumbledore'])\n",
        "predicted_sentence_2 = 'Dumbledore ' + ' '.join(predicted_sentence_2)\n",
        "\n",
        "print(f'Predicted sentence for Dumbledore: \\n{predicted_sentence_2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PksLKWl9Qo4R"
      },
      "source": [
        "# Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQi6QeHuMWqh",
        "outputId": "e58ff2bb-f6fe-448c-f098-1d04bc8dfd7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 words for context [\"harry\", \"potter\"]: [(0.21428571428571427, 'the'), (0.14285714285714285, 'was'), (0.07142857142857142, 'who'), (0.07142857142857142, 'wasnt'), (0.07142857142857142, 'voldemorts')]\n"
          ]
        }
      ],
      "source": [
        "def top_k_words_generator(context, k, model=mle_lm):\n",
        "    context = [context[-1]] # Coz bigrams\n",
        "    score_word = [(model.score(word, context), word) for word in model.vocab]\n",
        "\n",
        "    score_word.sort(reverse=True)\n",
        "    return score_word[:k]\n",
        "\n",
        "print(f'Top 5 words for context [\"harry\", \"potter\"]: {top_k_words_generator(context=[\"harry\", \"potter\"], k=5, model=mle_lm)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "k49RFEQAL-wZ"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "def beam_search(context, k, max_depth, model, num_outputs, debug=False):\n",
        "    q = deque()\n",
        "    q.append([1.0, context, 1]) # [probability, context, depth]\n",
        "    final_sentences = []\n",
        "    while len(q) != 0:\n",
        "        [prob, context, depth] = q.popleft()\n",
        "        top_k_words = top_k_words_generator(context, k, model)\n",
        "        for [word_prob, word] in top_k_words:\n",
        "            new_context = context.copy()\n",
        "            new_context.append(word)\n",
        "            if depth < max_depth:\n",
        "                if debug: \n",
        "                    print(f'Depth: {depth}, Context: {\" \".join(new_context)}, p = {prob * word_prob:0.4f}')\n",
        "                q.append([prob * word_prob, new_context, depth + 1])\n",
        "            else:\n",
        "                final_sentences.append([prob, new_context])\n",
        "\n",
        "    final_sentences.sort(reverse=True)\n",
        "    return final_sentences[:num_outputs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcaNm8PMxRgL",
        "outputId": "c1501ab4-1f09-4178-a5df-134ea91dba2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentences for context [\"harry\", \"potter\"]\n",
            "1) harry potter was a large pink beach ball wearing square glasses and  [p=4.052906145562826e-06]\n",
            "2) harry potter was a large pink beach ball wearing square glasses </s>  [p=4.052906145562826e-06]\n",
            "3) harry potter the dursleys had a large pink beach ball wearing square  [p=4.800762058886991e-07]\n",
            "4) harry potter the dursleys had a large pink beach ball wearing a  [p=4.800762058886991e-07]\n",
            "5) harry potter was a large pink beach ball wearing a large tawny  [p=3.699748348646563e-07]\n"
          ]
        }
      ],
      "source": [
        "predicted_sentences_1 = beam_search([\"harry\", \"potter\"], k=2, max_depth=10, model=mle_lm, num_outputs=5, debug=False)\n",
        "\n",
        "print('Predicted sentences for context [\"harry\", \"potter\"]')\n",
        "for i, [p, s] in enumerate(predicted_sentences_1):\n",
        "    print(f'{i+1}) {\" \".join(s)}  [{p=}]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted sentences for context [\"dumbledore\"]\n",
            "1) dumbledore you cant take him in his aunt petunia </s> â€˜ [p=2.346560298042777e-08]\n",
            "2) dumbledore you cant take him in his aunt petunia </s> zoo [p=2.346560298042777e-08]\n",
            "3) dumbledore you cant take him in his aunt petunia had been [p=1.9554669150356473e-08]\n",
            "4) dumbledore you cant take him in his aunt petunia had a [p=1.9554669150356473e-08]\n",
            "5) dumbledore you know what looked like yourself should have been watching [p=1.9058354930107985e-08]\n"
          ]
        }
      ],
      "source": [
        "predicted_sentences_2 = beam_search([\"dumbledore\"], k=2, max_depth=10, model=mle_lm, num_outputs=5, debug=False)\n",
        "\n",
        "print('Predicted sentences for context [\"dumbledore\"]')\n",
        "for i, [p, s] in enumerate(predicted_sentences_2):\n",
        "    print(f'{i+1}) {\" \".join(s)} [{p=}]')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9qwUXItv5iEt",
        "-u_C7Yxw-Xjk",
        "3tg9I5r2-YbK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

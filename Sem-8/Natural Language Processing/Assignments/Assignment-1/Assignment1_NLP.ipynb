{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2hc7ThQW3WiS"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eV1TeaEss-k3"
      },
      "outputs": [],
      "source": [
        "#Defining constants\n",
        "BP = 1\n",
        "N = 4\n",
        "w_n = 1 / N\n",
        "epsilon = 1e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OIpNGLXvxnv"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reb1Iwon-85W"
      },
      "source": [
        "### Preprocessing Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xmwnbxnn3oQb"
      },
      "outputs": [],
      "source": [
        "# Removing the punctuations from the text\n",
        "def remPunctuations(text):\n",
        "    # Table is a translation table for removing the punctuation marks from the words\n",
        "    table = str.maketrans({key: None for key in string.punctuation})\n",
        "    translated = text.translate(table)\n",
        "    return translated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qV1pMoWW4TO_"
      },
      "outputs": [],
      "source": [
        "# Lowercasing of text\n",
        "def toLower(text):\n",
        "    return text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B7WFtJue-rxC"
      },
      "outputs": [],
      "source": [
        "# Splitting the text based on the delimiter (in this case, space)\n",
        "def splitText(text):\n",
        "    return text.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KurdogmR--6-"
      },
      "source": [
        "### BLEU Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4eiNftUp_DD7"
      },
      "outputs": [],
      "source": [
        "# Given the text array and n, it will find all the n-grams for the given text\n",
        "def nGramGenerator(text, n):\n",
        "    nGramCount = {}\n",
        "    numOfTokens = len(text)\n",
        "\n",
        "    for i in range(numOfTokens - n + 1):\n",
        "        nGramString = \"\"\n",
        "        for j in range(i, i + n):\n",
        "            nGramString += text[j]\n",
        "\n",
        "        # Increase the frequency of the string in the dictionary\n",
        "        if nGramString in nGramCount:\n",
        "            nGramCount[nGramString] += 1\n",
        "        else:\n",
        "            nGramCount[nGramString] = 1\n",
        "\n",
        "    return nGramCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B88wFx5QsskU"
      },
      "outputs": [],
      "source": [
        "# Computing the modified n-gram precision given the 2 texts\n",
        "def generate_p_array(text1, text2):\n",
        "    # Preprocessing the texts\n",
        "    preprocessedString1 = splitText(toLower(remPunctuations(text1)))\n",
        "    preprocessedString2 = splitText(toLower(remPunctuations(text2)))\n",
        "\n",
        "    numOfTokens1 = len(preprocessedString1)\n",
        "    numOfTokens2 = len(preprocessedString2)\n",
        "\n",
        "    p = [0]\n",
        "\n",
        "    for n in range(1, min(numOfTokens1, numOfTokens2) + 1):\n",
        "        nGramCount1 = nGramGenerator(preprocessedString1, n)\n",
        "        nGramCount2 = nGramGenerator(preprocessedString2, n)\n",
        "\n",
        "        val = 0\n",
        "        for nGram, cnt1 in nGramCount1.items():\n",
        "            if nGram in nGramCount2:\n",
        "                val += min(cnt1, nGramCount2[nGram])\n",
        "\n",
        "        val /= (numOfTokens1 - n + 1)\n",
        "        p.append(val)\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N592gOQxAwnK"
      },
      "outputs": [],
      "source": [
        "# Computing the BLEU score using the modified n-gram precision\n",
        "def bleu_score_compute(p):\n",
        "    bleu_score = 0\n",
        "\n",
        "    for i in range(1, N+1):\n",
        "        if p[i] > epsilon:\n",
        "            bleu_score += w_n * math.log(p[i])\n",
        "\n",
        "    bleu_score = math.exp(bleu_score)\n",
        "    bleu_score *= BP\n",
        "\n",
        "    return bleu_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBiyAVXpv2ht"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS9ATVcmE1t5"
      },
      "source": [
        "### Computing BLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x44Qg2dCE6dE"
      },
      "outputs": [],
      "source": [
        "inputs = [[\"The boys were playing happily on the ground.\", \"The boys were playing football on the field.\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dKWl0Estlo0",
        "outputId": "6da33e82-8093-4313-f882-b8e5f7d39272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4111336169005197\n"
          ]
        }
      ],
      "source": [
        "for inputPair in inputs:\n",
        "    p = generate_p_array(inputPair[0], inputPair[1])\n",
        "    print(bleu_score_compute(p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-SsvrXewPtt"
      },
      "source": [
        "# Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTMWG6q74wts"
      },
      "source": [
        "We are taking minimum in the calculation of $p_n$ because we don't want to exceed the largest count observed, for each n-gram in the machine translated text, with the ground truth.\n",
        "\n",
        "So, the truncated count is always less than or equal to the n-gram's count in the ground truth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5_lesQW4uN6"
      },
      "source": [
        "# Question 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oeMvVFNnGBh8"
      },
      "outputs": [],
      "source": [
        "inputs = [[\"I have three apples and two oranges\", \"I have some apples and some oranges\"],\n",
        "          [\"I have three apples and two oranges\", \"Have three apples I and two oranges\"],\n",
        "          [\"a a a a a \", \"a a a a a a a a a\"],\n",
        "          [\"I had the cookie\", \"I had the cake\"],\n",
        "          [\"I had the cookie\", \"I had a cookie\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjtXqx6W5H5O",
        "outputId": "9538181c-81de-4059-fa05-b4c164bcf7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6985342056580097\n",
            "0.7186082239261684\n",
            "1.0\n",
            "0.7071067811865475\n",
            "0.7071067811865475\n"
          ]
        }
      ],
      "source": [
        "for inputPair in inputs:\n",
        "    p = generate_p_array(inputPair[0], inputPair[1])\n",
        "    print(bleu_score_compute(p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvxpH_tj6WMe"
      },
      "source": [
        "The potential disadvantages of BLEU score are:\n",
        "*   **It does not capture the meaning of the sentences**: This can be seen in the 4th and 5th pairs of sentences. Both the pairs return the same score even though the meaning is completely different.\n",
        "*   **It does not check the sentence structure properly**: The second pair has a higher score than the first pair even though the grammar of the second pair does not make the sentence meaningful.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
